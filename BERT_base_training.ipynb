{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba496a37-aecc-40d3-8fe0-f29413bb3158",
   "metadata": {
    "tags": []
   },
   "source": [
    "# BERT Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e742afcd-c3f6-440f-84d4-b19bdeebd80f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9925d9b-2387-40c0-9488-1df5c45760e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #for config setup \n",
    "# !pip install \"sagemaker==2.198\" \"transformers==4.21.1\" \"datasets==2.9\" \"torch==1.11.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2342cd76-04bb-4654-88fa-7eeedcc67f00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q \"sagemaker==2.198\" \"transformers==4.26.0\" \"datasets==2.9\" \"torch==1.13.1\" \"tqdm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48690518-01f2-41de-aee6-dbed644b9d6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "import boto3\n",
    "import datasets\n",
    "import transformers\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset, load_from_disk, Dataset, DatasetDict\n",
    "from datasets.filesystems import S3FileSystem\n",
    "from transformers import TrainingArguments, Trainer,AutoConfig,AutoTokenizer\n",
    "from sagemaker.huggingface import HuggingFace, TrainingCompilerConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "694e9d06-b963-4758-891d-28a745dd05fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0\n"
     ]
    }
   ],
   "source": [
    "print(datasets.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9db583-7e90-46a0-a0ed-d9816893c11f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## BERT Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5f47eac-10a3-4297-8b6c-1c7e43705f93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker role arn: arn:aws:iam::956796298028:role/service-role/AmazonSageMaker-ExecutionRole-20211005T133138\n",
      "sagemaker bucket: sagemaker-studio-ai-lab-3\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "#Set up sagemaker session\n",
    "sess = sagemaker.Session()\n",
    "sagemaker_session_bucket='sagemaker-studio-ai-lab-3'\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f96498c4-1cf8-4123-a954-0ebf9f3bd2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [13:53<00:00, 11.90s/it]\n"
     ]
    }
   ],
   "source": [
    "# #loading in data\n",
    "dfs = []\n",
    "for load_num in tqdm(range(0,70)):\n",
    "    df = pd.read_json(f's3://sagemaker-studio-ai-lab-3/final-data/data_{load_num}.json') \n",
    "    dfs.append(df)\n",
    "reviews = pd.concat (dfs, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ce4c0df-3ae1-4d1f-b004-aa72b5ee9994",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#subsetting to guarantee even distribution of stars for BERT\n",
    "reviews.r_stars.value_counts()\n",
    "balanced_df = reviews.groupby('r_stars',as_index = False,group_keys=False).apply(lambda s: s.sample(60000,replace=True)).sample(frac=1)\n",
    "balanced_df = balanced_df[['r_stars', 'r_text']]\n",
    "balanced_df['r_stars'] = balanced_df['r_stars'] -1 #change indexing lables to 0 indexing for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8993af20-2ade-4cbb-8998-13b83446cb0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#formatting as dataset object from huggingface\n",
    "dataset = Dataset.from_pandas(balanced_df, preserve_index=False)\n",
    "splits = dataset.train_test_split(test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91e4c159-3de9-40b7-b2ac-26166dcf2483",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b734108a34334dafa9e4d9ae1687adab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eb6afb7a1d5497280310cb81cdba832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#tokenizer\n",
    "tokenizer_name = 'bert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "# Helper function to get the content to tokenize\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['r_text'], padding='max_length', truncation=True, max_length = 512)\n",
    "\n",
    "# Tokenize\n",
    "train_dataset = splits['train'].map(tokenize, batched=True, batch_size=len(splits['train']))\n",
    "test_dataset = splits['test'].map(tokenize, batched=True, batch_size=len(splits['test']))\n",
    "\n",
    "# Set the format to PyTorch\n",
    "train_dataset = train_dataset.rename_column(\"r_stars\", \"labels\")\n",
    "train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "test_dataset = test_dataset.rename_column(\"r_stars\", \"labels\")\n",
    "test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c0dfa4-5c60-4777-b428-46a755896008",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(splits['train'][0]['r_text'])\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "648ff17a-fd38-4016-b194-578481d3cb29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:1307: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/2 shards):   0%|          | 0/210000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/90000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded training data to s3://sagemaker-studio-ai-lab-3/samples/datasets/tokenized_reviews_v4/train\n",
      "Uploaded testing data to s3://sagemaker-studio-ai-lab-3/samples/datasets/tokenized_reviews_v4/test\n"
     ]
    }
   ],
   "source": [
    "#upload to s3 for training\n",
    "import botocore\n",
    "from datasets.filesystems import S3FileSystem\n",
    "\n",
    "# Upload to S3\n",
    "s3 = S3FileSystem()\n",
    "s3_prefix = f'samples/datasets/tokenized_reviews_v4'\n",
    "training_input_path = f's3://{sess.default_bucket()}/{s3_prefix}/train'\n",
    "train_dataset.save_to_disk(training_input_path, fs = s3)\n",
    "test_input_path = f's3://{sess.default_bucket()}/{s3_prefix}/test'\n",
    "test_dataset.save_to_disk(test_input_path, fs=s3)\n",
    "\n",
    "print(f'Uploaded training data to {training_input_path}')\n",
    "print(f'Uploaded testing data to {test_input_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb4dd3f-cb9c-4796-a117-8001d6839b1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#with out config\n",
    "#defining hyperparameters and training the BERT model\n",
    "training_job_name=f'LA-bert-base-60k-v2'\n",
    "hyperparameters = {'epochs':3, \n",
    "                   'train_batch_size': 12, #32\n",
    "                   'model_name': 'bert-base-uncased',\n",
    "                   'num_labels': 5\n",
    "                  }\n",
    "hyperparameters[\"learning_rate\"] = float(\"5e-5\") / 32 * hyperparameters[\"train_batch_size\"]\n",
    "volume_size = 100\n",
    "huggingface_estimator = HuggingFace(entry_point='train.py', \n",
    "                                    source_dir='./scripts',\n",
    "                                    output_path = 's3://{}/{}/{}'.format(sagemaker_session_bucket, s3_prefix, 'bert_model'),\n",
    "                                    code_location = 's3://{}/{}/{}'.format(sagemaker_session_bucket, s3_prefix, 'custom_code'),\n",
    "                                    instance_type='ml.g4dn.12xlarge',\n",
    "                                    instance_count=1,\n",
    "                                    role=role,\n",
    "                                    transformers_version='4.26.0',\n",
    "                                    pytorch_version= '1.13.1',\n",
    "                                    py_version='py39',\n",
    "                                    hyperparameters=hyperparameters,\n",
    "                                    base_job_name = training_job_name,\n",
    "                                    volume_size = volume_size\n",
    "                                   )\n",
    "huggingface_estimator.fit({'train': training_input_path, 'test': test_input_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c23d4677-73c3-4866-81c2-55a5332d16b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "container image used for training job: \n",
      "None\n",
      "\n",
      "s3 uri where the trained model is located: \n",
      "s3://sagemaker-studio-ai-lab-3/samples/datasets/tokenized_reviews_v2/bert_model/LA-bert-45k-v1-2023-12-02-03-29-43-447/output/model.tar.gz\n",
      "\n",
      "latest training job name for this estimator: \n",
      "LA-bert-45k-v1-2023-12-02-03-29-43-447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# container image used for training job\n",
    "print(f\"container image used for training job: \\n{huggingface_estimator.image_uri}\\n\")\n",
    "\n",
    "# s3 uri where the trained model is located\n",
    "print(f\"s3 uri where the trained model is located: \\n{huggingface_estimator.model_data}\\n\")\n",
    "\n",
    "# latest training job name for this estimator\n",
    "print(f\"latest training job name for this estimator: \\n{huggingface_estimator.latest_training_job.name}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482d0bc3-a31d-44d6-b66f-eb7acc999ef1",
   "metadata": {},
   "source": [
    "Next steps: optimize efficiency of model or just go straight to pulling predictions and then using them as input bc that'll be hard enough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b302ec-d100-4479-8bdd-e86979005f1e",
   "metadata": {},
   "source": [
    "Hyp tuning. If have time do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ed0b77-da98-498f-a5c5-deb77d587776",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {\"learning_rate\": ContinuousParameter(0.0001, 0.1),\n",
    "                         \"warmup_steps\": IntegerParameter(100, 500),\n",
    "                         \"optimizer\": CategoricalParameter([\"AdamW\", \"Adafactor\"]),\n",
    "                         \"weight_decay\": ContinuousParameter(0.00, 0.001)}\n",
    "\n",
    "objective_metric = \"loss\"\n",
    "objective_type = \"Minimize\"\n",
    "metric_definitions = [{\"Name\": \"loss\", \"Regex\": \"loss = ([0-9\\\\.]+)\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e744f06e-3a42-4f9c-9e02-beb1093b4f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(huggingface_model, #have to use the current estimator here. \n",
    "                            objective_metric,\n",
    "                            hyperparameter_ranges,\n",
    "                            metric_definitions,\n",
    "                            max_jobs=3,\n",
    "                            max_parallel_jobs=1,\n",
    "                            objective_type=objective_type)\n",
    "tuner.fit(inputs={\"train\": r\"s3://sagemaker-studio-ai-lab-3/samples/datasets/tokenized_reviews_v2/train\", \"test\": \"s3://sagemaker-studio-ai-lab-3/samples/datasets/tokenized_reviews_v2/test\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159e9d9e-0b20-4a2c-85c4-7f8e26ee7ce1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### scratch work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33082957-b553-4aae-b3aa-1f9afbf3a002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #defining hyperparameters and training the BERT model using config (supposed to be 50% improvement?)\n",
    "# training_job_name=f'LA-bert-45k-v1'\n",
    "# hyperparameters = {'epochs':3, \n",
    "#                    'train_batch_size': 24,\n",
    "#                    'model_name': 'bert-base-uncased',\n",
    "#                    'num_labels': 5\n",
    "#                   }\n",
    "# compiler_config=TrainingCompilerConfig()\n",
    "# volume_size = 50\n",
    "# huggingface_estimator = HuggingFace(entry_point='train.py', \n",
    "#                                     source_dir='./scripts',\n",
    "#                                     output_path = 's3://{}/{}/{}'.format(sagemaker_session_bucket, s3_prefix, 'bert_model'),\n",
    "#                                     code_location = 's3://{}/{}/{}'.format(sagemaker_session_bucket, s3_prefix, 'custom_code'),\n",
    "#                                     instance_type='ml.g4dn.2xlarge', #ml.p2.xlarge\n",
    "#                                     instance_count=1,\n",
    "#                                     role=role,\n",
    "#                                     transformers_version='4.21.1',\n",
    "#                                     pytorch_version= '1.11.0',\n",
    "#                                     py_version='py38',\n",
    "#                                     hyperparameters=hyperparameters,\n",
    "#                                     base_job_name = training_job_name,\n",
    "#                                     volume_size = volume_size,\n",
    "#                                     disable_profiler=True,\n",
    "#                                     debugger_hook_config=False,\n",
    "#                                     compiler_config=compiler_config\n",
    "#                                    )\n",
    "# huggingface_estimator.fit({'train': training_input_path, 'test': test_input_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bf52dc-0f5f-4b7c-80f3-ba604542c1f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # BERT Model for text encoding\n",
    "# tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(reviews['r_text'][0:10000], reviews['r_stars'][0:10000], test_size=0.2, random_state=42)\n",
    "\n",
    "# X_all_encoded = tokenizer.batch_encode_plus(reviews['r_text'].tolist(), padding=True, truncation=True, max_length = 128, return_tensors='tf')\n",
    "# X_train_encoded = tokenizer.batch_encode_plus(X_train.tolist(), padding=True,  truncation=True, max_length = 128, return_tensors='tf')\n",
    "# X_test_encoded = tokenizer.batch_encode_plus(X_test.tolist(),  padding=True,  truncation=True, max_length = 128, return_tensors='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a394c977-8787-4144-9ef4-bff1d5326438",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #example of using tokenizer on one sentence\n",
    "# tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "# tokenized_output_default = tokenizer(list(reviews['r_text'][0:100]), truncation=True, max_length = 128)\n",
    "# input_ids = tokenized_output_default['input_ids'][2]\n",
    "# tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "# print(reviews['r_text'][2])\n",
    "# print(tokens)\n",
    "# print(input_ids)\n",
    "\n",
    "# #print(\"Default (is_split_into_words=False):\", tokenized_output_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7da5b6-43d5-42de-9cd1-d75693627524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenize_and_align_labels(reviews):\n",
    "#     tokenized_inputs = tokenizer(list(reviews[\"r_text\"]), truncation=True, max_length = 128, padding = True)\n",
    "#     labels = []\n",
    "#     for i, label in enumerate(examples[f\"ner_tags\"]):\n",
    "#         word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "#         previous_word_idx = None\n",
    "#         label_ids = []\n",
    "#         for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "#             if word_idx is None:\n",
    "#                 label_ids.append(-100)\n",
    "#             elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "#                 label_ids.append(label[word_idx])\n",
    "#             else:\n",
    "#                 label_ids.append(-100)\n",
    "#             previous_word_idx = word_idx\n",
    "#         labels.append(label_ids)\n",
    "\n",
    "#     tokenized_inputs[\"labels\"] = labels\n",
    "#     return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a5452a-d60c-44ab-bb25-a24e8b88ae75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# labels = ['1','2','3','4','5']\n",
    "# id2label = {idx:label for idx, label in enumerate(labels)}\n",
    "# label2id = {label:idx for idx, label in enumerate(labels)}\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# def preprocess_data(examples):\n",
    "#     text = examples[\"r_text\"]\n",
    "#     encoding = tokenizer(text, padding=True, truncation=True, max_length=128)\n",
    "#     labels_batch = {label: examples[examples] for label in labels} #label:text key-value pairs\n",
    "#     labels_matrix = np.zeros((len(text), len(labels)))\n",
    "#     for idx, label in enumerate(labels):\n",
    "#         labels_matrix[:, idx] = labels_batch[label]\n",
    "#     encoding[\"labels\"] = labels_matrix.tolist()\n",
    "#     return encoding\n",
    "\n",
    "# encoded_dataset = dataset.select(range(100)).map(preprocess_data, batched=True, remove_columns=dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e955e066-6b6f-4d71-bdc4-ada461edac0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #raw_datasets = Dataset.from_pandas(reviews)\n",
    "# raw_datasets.select(range(100))['r_text']\n",
    "# dataset = Dataset.from_pandas(reviews)\n",
    "# list_of_word_lists = [sentence.split() for sentence in dataset['r_text'][0:10]]\n",
    "# list_of_word_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ed3505-835a-4559-aa10-b2b8e15d6c10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #tokenizer for BERT\n",
    "# model_checkpoint = \"bert-base-cased\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "# def align_labels_with_tokens(labels, word_ids):\n",
    "#     new_labels = []\n",
    "#     current_word = None\n",
    "#     for word_id in word_ids:\n",
    "#         if word_id != current_word:\n",
    "#             current_word = word_id\n",
    "#             label = -100 if word_id is None else labels[word_id]\n",
    "#             new_labels.append(label)\n",
    "#         elif word_id is None:\n",
    "#             new_labels.append(-100)\n",
    "#         else:\n",
    "#             label = -100\n",
    "#             new_labels.append(label)\n",
    "#     return new_labels\n",
    "\n",
    "# def tokenize_and_align_labels(examples):\n",
    "#     tokenized_inputs = tokenizer(examples[\"r_text\"], truncation=True, max_length = 128, padding = True, is_split_into_words=True)\n",
    "#     all_labels = examples[\"r_stars\"]\n",
    "#     new_labels = []\n",
    "#     for i, labels in enumerate(all_labels):\n",
    "#         word_ids = tokenized_inputs.word_ids(i)\n",
    "#         new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "#     tokenized_inputs[\"labels\"] = new_labels\n",
    "#     return tokenized_inputs\n",
    "\n",
    "# #Tokenize the Dataset\n",
    "# tokenized_datasets = raw_datasets.select(range(100)).map(\n",
    "#     tokenize_and_align_labels,\n",
    "#     batched=True,\n",
    "#     remove_columns=raw_datasets.column_names,\n",
    "# )\n",
    "# tokenized_datasets.set_format(\"torch\", columns = ['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# # def tokenize_and_align_labels(reviews):\n",
    "# #     tokenized_inputs = tokenizer(reviews['r_text'].tolist(), truncation=True, max_length = 128,padding=True, return_tensors='pt')\n",
    "# #     all_labels = reviews['r_stars'].tolist()\n",
    "# #     new_labels = []\n",
    "# #     for i, labels in enumerate(all_labels):\n",
    "# #         # word_ids = tokenized_inputs.word_ids(i)\n",
    "# #         # new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "# #         new_labels.append(align_labels_with_tokens(labels, tokenized_inputs['input_ids'][i].tolist()))\n",
    "# #     tokenized_inputs[\"labels\"] = new_labels\n",
    "# #     return tokenized_inputs\n",
    "# # tokenized_datasets = tokenize_and_align_labels(reviews)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
